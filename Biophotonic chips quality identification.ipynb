{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biophotonic chips quality identification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import package required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Automatic_SampleSelection:\n",
    "    def __init__(self, image_path, output_folder, SelectSize=0.1):\n",
    "        self.image = cv2.imread(image_path)\n",
    "        self.output_folder = output_folder\n",
    "        self.roi_indices = []\n",
    "        self.SelectSize=SelectSize\n",
    "        \n",
    "    def Auto_Selection(self):\n",
    "        # Extract the red channel of the image\n",
    "        red_channel = self.image[:, :, 2]\n",
    "    \n",
    "        # Apply thresholding to the grayscale image to create a binary image\n",
    "        _, thresh = cv2.threshold(red_channel, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "        # Find contours in the binary image\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "        # Sort contours from top to bottom, left to right\n",
    "        contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[1] * self.image.shape[1] + cv2.boundingRect(c)[0])\n",
    "        centerX=[]\n",
    "        centerY=[]\n",
    "        height=[]\n",
    "        width=[]\n",
    "    \n",
    "        # Iterate through each contour and find the bounding box\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "    \n",
    "            # Check if the rectangle is at least 50x50 pixels\n",
    "            if w >= 50 and h >= 50 and abs(w - h) <= 15:\n",
    "                # Select the ROI and save it as a separate image\n",
    "                cen_x=int((x+(x+w))/2)\n",
    "                cen_y=int((y+(y+h))/2)\n",
    "                hei=int(self.SelectSize*h)\n",
    "                wid=int(self.SelectSize*w)\n",
    "                Sample=self.image[y:y+h, x:x+w]\n",
    "                roi=self.image[cen_y-hei:cen_y +hei, cen_x-wid:cen_x +wid]\n",
    "                centerX.append(cen_x)\n",
    "                centerY.append(cen_y)\n",
    "                height.append(hei)\n",
    "                width.append(wid)\n",
    "    \n",
    "                # Generate the filename for the ROI image\n",
    "                filename = 'ROI{}.jpg'.format(len(self.roi_indices))\n",
    "    \n",
    "                # Specify the output path for the ROI image\n",
    "                output_path = os.path.join(self.output_folder, filename)\n",
    "    \n",
    "                # Save the ROI image\n",
    "                cv2.imwrite(output_path, roi)\n",
    "    \n",
    "                # Show the sample as a separate plot with a label indicating the sample number\n",
    "                plt.imshow(cv2.cvtColor(Sample, cv2.COLOR_BGR2RGB))\n",
    "                plt.title('sample {}'.format(len(self.roi_indices)))\n",
    "                plt.show()\n",
    "    \n",
    "                # Show the ROI as a separate plot with a label indicating the ROI number\n",
    "                plt.imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "                plt.title('ROI {}'.format(len(self.roi_indices)))\n",
    "                plt.show()\n",
    "    \n",
    "                # Draw the bounding box on the original image with ROI number\n",
    "                cv2.rectangle(self.image, (x, y), (x + w, y + h), (0, 255,0), 2)\n",
    "                cv2.rectangle(self.image, (cen_x-wid, cen_y-hei), \n",
    "                              (cen_x + wid, cen_y + hei), (0,0,255), 2)\n",
    "                # Add text with ROI number\n",
    "                cv2.putText(self.image, str(len(self.roi_indices)), (x, y - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    \n",
    "                # Increment roi_indices by 1\n",
    "                self.roi_indices.append(1)\n",
    "    \n",
    "        # Show the resulting image using matplotlib\n",
    "        plt.imshow(cv2.cvtColor(self.image, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        image_coor=pd.DataFrame({'centerX':centerX,'centerY':centerY,\n",
    "                                 'height':height,'width':width})\n",
    "        image_coor.to_csv('image_coord.csv')\n",
    "        print(image_coor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    def __init__(self, image_path):\n",
    "        self.image_path = image_path\n",
    "        self.image_name = os.path.basename(image_path)\n",
    "        self.image = cv2.imread(image_path)\n",
    "        self.rgb_data = self.extract_RGB_data()\n",
    "        self.df = self.process_image()\n",
    "\n",
    "    def extract_RGB_data(self):\n",
    "        # Split RGB channels\n",
    "        b, g, r = cv2.split(self.image)\n",
    "        return np.array([r, g, b]).reshape(self.image.shape)\n",
    "\n",
    "    def rgb_to_wavelength(self, rgb):\n",
    "        # Normalize RGB values\n",
    "        normalized_rgb = [val / 255.0 for val in rgb]\n",
    "\n",
    "        # Calculate the dominant wavelength\n",
    "        max_val = max(normalized_rgb)\n",
    "        min_val = min(normalized_rgb)\n",
    "        wavelength = (max_val - min_val) * 100 + 400\n",
    "\n",
    "        # Calculate the standard deviation of RGB values\n",
    "        std_dev = np.std(rgb)\n",
    "\n",
    "        # Calculate the error in wavelength estimation\n",
    "        error = std_dev * 100\n",
    "\n",
    "        return wavelength, error\n",
    "\n",
    "    def process_image(self):\n",
    "        # Convert RGB data to wavelength\n",
    "        wavelengths = []\n",
    "        errors = []\n",
    "\n",
    "        for i in range(self.rgb_data.shape[0]):  # Loop over rows\n",
    "            for j in range(self.rgb_data.shape[1]):\n",
    "                w, e = self.rgb_to_wavelength(self.rgb_data[i,j,:])\n",
    "                wavelengths.append(w)\n",
    "                errors.append(e)\n",
    "\n",
    "        # Create a dataframe with the wavelength and error data\n",
    "        df = pd.DataFrame({'Wavelength': wavelengths, 'Error': errors})\n",
    "\n",
    "        # Plot the wavelength data\n",
    "        ax = sns.violinplot(x=df['Wavelength'])\n",
    "        ax.set_title(self.image_name)\n",
    "        plt.show()\n",
    "        return df['Wavelength']\n",
    "\n",
    "class FolderProcessor:\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.overall_data = self.process_images()\n",
    "\n",
    "    def process_images(self):\n",
    "        # Iterate over files in the folder\n",
    "        overall_data = pd.DataFrame()\n",
    "        for filename in os.listdir(self.folder_path):\n",
    "            # Check if the file is an image file\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(self.folder_path, filename)\n",
    "                image_processor = ImageProcessor(image_path)\n",
    "                overall_data[filename[3:-4]] = image_processor.df\n",
    "\n",
    "        # Create a larger figure\n",
    "        plt.figure(figsize=(10, 8))\n",
    "\n",
    "        # Plot all the data\n",
    "        ax = sns.violinplot(data=overall_data, inner='stick')\n",
    "        ax.set(xlabel='Sample', ylabel='Wavelength')\n",
    "        plt.show()\n",
    "\n",
    "        return overall_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorUniformityAnalyzer:\n",
    "    def __init__(self, image_path):\n",
    "        self.image_path = image_path\n",
    "\n",
    "    def calculate_color_uniformity(self):\n",
    "        # Load the image\n",
    "        image = cv2.imread(self.image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Reshape the image to a flat array\n",
    "        pixels = image.reshape(-1, 3)\n",
    "\n",
    "        # Calculate the standard deviation of color values\n",
    "        std_dev = np.std(pixels, axis=0)\n",
    "\n",
    "        # Calculate the mean of the standard deviation across color channels\n",
    "        self.uniformity_score = np.mean(std_dev)\n",
    "\n",
    "        # Plot the histogram\n",
    "        self._plot_histogram(pixels)\n",
    "\n",
    "        print('Color Uniformity Score:', self.uniformity_score)\n",
    "    \n",
    "        return self.uniformity_score\n",
    "\n",
    "    def _plot_histogram(self, pixels):\n",
    "        # Extract the file name from the image path\n",
    "        file_name = os.path.basename(self.image_path)\n",
    "\n",
    "        # Calculate the histogram\n",
    "        hist, bins = np.histogram(pixels.flatten(), bins=256, range=[0, 256])\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title('Color Histogram - ' + file_name)\n",
    "        plt.xlabel('Pixel Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.plot(hist, color='gray')\n",
    "        plt.xlim([0, 256])\n",
    "        plt.text(10, np.max(hist) - np.max(hist) * 0.1, f'Uniformity Score: {self.uniformity_score:.2f}', fontsize=12, color='black')\n",
    "        plt.show()\n",
    "        \n",
    "class FolderProcessorUniformaty:\n",
    "    def __init__(self, folder_path, automatic_selection):\n",
    "        self.folder_path = folder_path\n",
    "        self.select_size = automatic_selection.SelectSize\n",
    "        self.overall_data = self.process_images()\n",
    "\n",
    "    def process_images(self):\n",
    "        fileNames = [] # List to store file names\n",
    "        uniformity = [] # List to store uniformity scores\n",
    "\n",
    "        for filename in os.listdir(self.folder_path):\n",
    "            # Check if the file is an image file\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(self.folder_path, filename)\n",
    "                \n",
    "                # Perform image processing or analysis here\n",
    "                # Assuming you have a ColorUniformityAnalyzer class that calculates uniformity\n",
    "                analyzer = ColorUniformityAnalyzer(image_path)\n",
    "                uniformity_score = analyzer.calculate_color_uniformity()\n",
    "                \n",
    "                # Store the file name and uniformity score in respective lists\n",
    "                fileNames.append(filename[:-4])\n",
    "                uniformity.append(uniformity_score)\n",
    "                \n",
    "                print('Color Uniformity Score:', uniformity_score)\n",
    "\n",
    "        # Create a dictionary from the lists\n",
    "        data = {'File Name': fileNames, str(self.select_size): uniformity}\n",
    "\n",
    "        # Create a DataFrame from the dictionary\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        path='C:/Users/james/Desktop/Surface plasma/Uniformaty_data/'\n",
    "        df.to_csv(str(path)+'uniformity_df_' + str(self.select_size) + '.csv', index=False)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code encompasses a Python implementation designed for conducting image processing and analysis tasks within a scientific context. Its purpose is to facilitate automated sample selection, wavelength analysis, and color uniformity assessment of images. Here is a comprehensive breakdown of the different classes and their associated functionalities, reflecting their academic value:\n",
    "\n",
    "1. `Automatic_SampleSelection`: This class addresses the automated selection of samples from an input image using specific criteria. It undertakes essential steps, such as extracting the red channel from the image, applying thresholding techniques to produce a binary image, and subsequently identifying contours. By considering size and aspect ratio, it proceeds to select rectangular regions of interest (ROIs) that satisfy predefined conditions. These ROIs are saved as individual images and visualized using the widely adopted `matplotlib.pyplot` library.\n",
    "\n",
    "2. `ImageProcessor`: Within this class, the provided code encompasses the processing of a single image. It effectively extracts the RGB data and performs conversions to wavelength values. This step is followed by the calculation of dominant wavelengths and error estimations, providing insight into the accuracy of the wavelength estimation process. The resultant wavelength and error data are organized in a structured manner using a pandas dataframe. Additionally, the visualization of the wavelength distribution is achieved through the utilization of the expressive `seaborn` library, employing a violin plot.\n",
    "\n",
    "3. `FolderProcessor`: The role of this class lies in managing multiple images within a specified folder. It engages in a systematic iteration over the files contained within the designated directory. By employing the capabilities of the `ImageProcessor` class, each image is individually processed, and its RGB data is extracted and converted into wavelength values. The collective wavelength data for all images is then structured within a pandas dataframe. Finally, an informative violin plot is generated to illustrate the overall distribution of wavelengths across the entire collection of images.\n",
    "\n",
    "4. `ColorUniformityAnalyzer`: This class offers a comprehensive means of assessing color uniformity in individual images. The initial step involves loading the image data and subsequently reshaping it into a flattened array. By calculating the standard deviation of color values, an evaluation of color uniformity is obtained. The mean of the standard deviations across the color channels is utilized as a representative uniformity score. Furthermore, the code includes the generation of a histogram plot depicting pixel values, with the resulting uniformity score prominently displayed as text, thereby enhancing the visual representation of the analysis.\n",
    "\n",
    "5. `FolderProcessorUniformaty`: This class extends the functionality of the folder processing operation to encompass the evaluation of color uniformity across a collection of images. It iterates through the files within the designated folder, employing the `ColorUniformityAnalyzer` class to calculate the color uniformity score for each image. The resulting uniformity scores, along with the corresponding file names, are collected and organized within lists. Subsequently, a pandas dataframe is constructed using these lists, facilitating further analysis and interpretation. Finally, the resulting dataframe is preserved in a CSV file, ensuring reproducibility and ease of access to the collected uniformity data.\n",
    "\n",
    "In conclusion, this codebase serves as a valuable academic resource, providing a practical implementation of image processing and analysis techniques. By automating sample selection, facilitating wavelength analysis, and enabling color uniformity assessment, it enhances research capabilities within scientific domains. The code embraces well-established libraries, such as `matplotlib.pyplot`, `seaborn`, and `pandas`, which are widely recognized within the academic community for their utility in data visualization, analysis, and storage."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the code and analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Automatic_SampleSelection import *\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize ROIAnalyzer object\n",
    "image_path = 'C:/Users/james/Desktop/Surface plasma/Oil_water_1/water001.JPG'\n",
    "output_folder = 'C:/Users/james/Desktop/Surface plasma/Oil_water_1/ROIs_1'\n",
    "\n",
    "# Process the image and analyze ROIs\n",
    "# Test the effect of SelectSize\n",
    "Selectsize_li = [SelectSi / 100 for SelectSi in range(10, 51, 1)]\n",
    "for num in Selectsize_li:\n",
    "    analyzer = Automatic_SampleSelection(image_path, output_folder, SelectSize=num)\n",
    "    analyzer.Auto_Selection()\n",
    "\n",
    "    # Process the ROIs and calculate uniformity\n",
    "    folder_path = \"C:/Users/james/Desktop/Surface plasma/Oil_water_1/ROIs_1\"\n",
    "    folder_processor = FolderProcessorUniformaty(folder_path, analyzer)\n",
    "\n",
    "    # Access the processed data\n",
    "    overall_data = folder_processor.overall_data\n",
    "    print(overall_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the effectiveness of Select size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = \"C:/Users/james/Desktop/Surface plasma/Uniformaty_data\"  # Specify the folder path where CSV files are located\n",
    "\n",
    "# Get a list of CSV file paths in the folder\n",
    "csv_files = glob.glob(folder_path + \"/*.csv\")\n",
    "\n",
    "# Initialize an empty list to store the individual DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Read each CSV file and append its DataFrame to the list\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs)\n",
    "\n",
    "merged_df = combined_df.groupby('File Name').sum()\n",
    "\n",
    "# Reset the index to make the 'File Name' column a regular column\n",
    "merged_df = merged_df.reset_index()\n",
    "\n",
    "print(merged_df)\n",
    "\n",
    "# Visualize the DataFrame\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x_axis = np.array([i for i in merged_df.columns[1:]])\n",
    "roi_names = merged_df['File Name']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "for i, roi in enumerate(roi_names):\n",
    "    values = merged_df.iloc[i, 1:].values.flatten()\n",
    "    ax.plot(x_axis, values, 'o--',alpha =0.8, label=roi)\n",
    "\n",
    "ax.set_xlabel('Selection Size')\n",
    "ax.set_ylabel('Uniformity score')\n",
    "ax.set_title('The effect of selection size on Uniformaty score')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "folder_path = \"C:/Users/james/Desktop/Surface plasma/Uniformaty_data\"  # Specify the folder path where CSV files are located\n",
    "\n",
    "# Get a list of CSV file paths in the folder\n",
    "csv_files = glob.glob(folder_path + \"/*.csv\")\n",
    "\n",
    "# Initialize an empty list to store the individual DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Read each CSV file and append its DataFrame to the list\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs)\n",
    "\n",
    "merged_df = combined_df.groupby('File Name').sum()\n",
    "\n",
    "# Reset the index to make the 'File Name' column a regular column\n",
    "merged_df = merged_df.reset_index()\n",
    "\n",
    "# Visualize the DataFrame in 3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x_axis = np.arange(len(merged_df.columns[1:]))\n",
    "y_axis = np.arange(len(merged_df['File Name']))\n",
    "X, Y = np.meshgrid(x_axis, y_axis)\n",
    "Z = merged_df.iloc[:, 1:].values\n",
    "\n",
    "surface = ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "\n",
    "ax.set_xlabel('Selection Size')\n",
    "ax.set_ylabel('File Name')\n",
    "ax.set_zlabel('Uniformity Score')\n",
    "ax.set_title('The effect of selection size on Uniformity score')\n",
    "\n",
    "# Add interactive rotation\n",
    "def update_plot(elev, azim):\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "# Connect the update_plot function to the mouse event\n",
    "fig.canvas.mpl_connect('motion_notify_event', lambda event: update_plot(event.ydata, event.xdata))\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
